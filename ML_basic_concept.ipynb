{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.欠拟合与过拟合\n",
    "在拟合模型过程中，不可避免的会产生误差。而误差的来源通常有两种： \n",
    "  \n",
    "  \n",
    "(1)偏差(bias),因模型无法表示基本数据的复杂度而造成的偏差。  \n",
    "模型复杂度过低，不能很好的拟合数据，造成偏差，准确率降低，训练误差大，导致欠拟合。  \n",
    "简单来说，在训练数据和测试数据上表现都很差。在训练数据的期望输出与实际真实输出差距很大。  \n",
    "\n",
    "避免欠拟合：增加模型复杂度，如采用高阶模型(预测)或者引入更多特征(分类)   \n",
    "  \n",
    "  \n",
    "(2).方差(variance),因模型对训练它所用的有限数据过于敏感而造成的方差。  \n",
    "模型复杂度过高，训练误差小，测试误差大，方差过大，导致过拟合。    \n",
    "简单来说，在训练样本得到的输出和期望输出基本一致，但是测试样本输出和测试样本的期望输出之间相差却很大。  \n",
    "  \n",
    "  避免过拟合: 降低模型复杂度，如加上正则惩罚项，如L1,L2，增加训练数据等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. 学习曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 方差分数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 之后要介绍学习曲线的东西\n",
    "测试集跟训练集的学习曲线的接近程度   \n",
    "解释欠拟合，过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.稀疏性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5.高方差\n",
    "为什么线性回归模型中存在多个相关变量时，系数确定性变差，并呈现高方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6. Laplace平滑\n",
    "拉普拉斯平滑又称加1平滑，是比较常用的平滑方法，解决零概率问题。  \n",
    "所谓零概率问题，就是在计算新实例等概率时，如果某个分量在训练集中从没出现过，会导致整个实例等概率计算结果为0.针对文本分类问题就是当一个词语在训练集中没有出现过，那么该词语的概率为0，使用朴素贝叶斯法或者n-gram模型计算文本出现的概率时，连乘导致整个文本出现的概率也为0.这显然是不合理的，我们不能因为一个事件没有观测到而判断该事件发生的概率为0.  \n",
    "解决办法：分子加1，分母加空k，这里k代表类别数。\n",
    "\n",
    "## 7. 贝叶斯m-估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 8.共轭分布\n",
    "在贝叶斯统计中，如果后验分布和先验分布属于同类，则先验分布和后验分布被称为共轭分布，先验分布被称为似然函数的共轭先验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.最大似然和最大后验- ？-贝叶斯估计，最小二乘之间的关系\n",
    "\n",
    "### 9.1 极大似然估计\n",
    " \n",
    "    \n",
    "极大似然估计法由高斯和费希尔先后提出，是被使用最广泛的一种参数估计方法，该方法建立的依据是直观的极大似然原理 -- “最像”就是“最大似然”之意。  \n",
    "最大似然背后的思想是，发生的即是合理的。最大似然，“似”即“像”，表示概率；“然”即“这样”，表示已观测到的数据。“最大似然”即找到一组参数，使得“像这样”的概率最大，即使得已观测到的事件的联合概率最大。  \n",
    "通俗理解来说，就是利用已知的样本结果信息，反推最具有可能(最大概率)导致这些样本结果出现的模型参数值。  \n",
    "换句话说，极大似然提供了一种给定观察数据来评估模型参数的方法，即:\"模型已定，参数未知。\"  当模型满足某个分布，它的参数值我通过极大似然估计法求出来。   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "极大似然估计的思想是：参数的估计是使得样本值出现的概率达到最大对应的参数值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10.条件期望\n",
    "随机变量E(X|Y)为随机变量X关于随机变量Y的条件数学期望。随机变量E(X|Y)是随机变量Y的函数。故有：\n",
    "$$E[X]=E[E[X|Y]]$$\n",
    "对于任何关于X，Y的函数f(X,Y),有：  \n",
    "$$E[f(X,Y)]=E_XE[f(X,Y)|X]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic回归和极大似然之间的关系\n",
    "事实上，最小二乘可以由高斯噪声假设+极大似然估计推导出来。当然极大似然估计还可以推导出其他的loss function,比如logistic回归中，loss function是交叉熵."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## sklearn中 Random_state的作用\n",
    "random_state相当于随机数种子，即random.seed()。   \n",
    "设置random_state可以让每次划分训练集和验证集的时候都是完全一样的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 没有设置随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 37 64 98 81 93 30 70 62 23 ------------\n",
      "20 69 57 49 97 60 6 2 18 59 "
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(10):\n",
    "    print(random.randint(1,100),end=' ')\n",
    "print('------------')\n",
    "for i in range(10):\n",
    "    print(random.randint(1,100),end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置随机数种子(相同的随机种子）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 35 12 99 53 35 14 5 49 69 ------------\n",
      "7 35 12 99 53 35 14 5 49 69 "
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "for i in range(10):\n",
    "    print(random.randint(1,100),end=' ')\n",
    "print('------------')\n",
    "random.seed(123)\n",
    "for i in range(10):\n",
    "    print(random.randint(1,100),end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置不同的随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 58 60 56 50 83 6 80 94 67 "
     ]
    }
   ],
   "source": [
    "random.seed(456)\n",
    "for i in range(10):\n",
    "    print(random.randint(1,100),end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $p(x;\\theta)$和$p(x|\\theta)$的区别\n",
    "在概率论中，求解极大似然估计时有两种表示方法，$p(x;\\theta)$和$p(x|\\theta)$。  \n",
    "在这里$p(x|\\theta)$并不总代表条件概率，(因为$\\theta$不总是随机变量)，也就是说$p(x|\\theta)$不代表条件概率时与$p(x;\\theta)$等价。  \n",
    "$p(x;\\theta)$写分号时，表示待估参数是固定的(只是当前未知)，加分号带参数是为了说明这里有个$\\theta$的参数，$p(x;\\theta)$的意思就是随机变量X=x在参数$\\theta$下的概率。  \n",
    "- 定义：  \n",
    "假定一个关于参数$\\theta$，具有离散型概率分布P的随机变量X，则在给定X的输出x时，参数的似然函数可表示为：  \n",
    "$$L(\\theta|x)=p_\\theta(x)=P_\\theta(X=x)$$\n",
    "其中，$p(x)$表示X取x时的概率。上式常常写为$P(X=x|\\theta)$或者$P(X=x;\\theta)$.需要注意的是，此处并非条件概率，因为$\\theta$并不(总)是随机变量。  \n",
    "> - 对于这两种表示法，频率学派和贝叶斯学派的分歧  \n",
    "(1)频率派认为参数为固定的值，是指真实世界中，参数值就是某个定值。  \n",
    "(2)贝叶斯学派认为参数是随机变量，是指取这个值是有一定概率的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
