{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.欠拟合与过拟合\n",
    "在拟合模型过程中，不可避免的会产生误差。而误差的来源通常有两种： \n",
    "  \n",
    "  \n",
    "(1)偏差(bias),因模型无法表示基本数据的复杂度而造成的偏差。  \n",
    "模型复杂度过低，不能很好的拟合数据，造成偏差，准确率降低，训练误差大，导致欠拟合。  \n",
    "简单来说，在训练数据和测试数据上表现都很差。在训练数据的期望输出与实际真实输出差距很大。  \n",
    "\n",
    "避免欠拟合：增加模型复杂度，如采用高阶模型(预测)或者引入更多特征(分类)   \n",
    "  \n",
    "  \n",
    "(2).方差(variance),因模型对训练它所用的有限数据过于敏感而造成的方差。  \n",
    "模型复杂度过高，训练误差小，测试误差大，方差过大，导致过拟合。    \n",
    "简单来说，在训练样本得到的输出和期望输出基本一致，但是测试样本输出和测试样本的期望输出之间相差却很大。  \n",
    "  \n",
    "  避免过拟合: 降低模型复杂度，如加上正则惩罚项，如L1,L2，增加训练数据等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. 学习曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 方差分数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 之后要介绍学习曲线的东西\n",
    "测试集跟训练集的学习曲线的接近程度   \n",
    "解释欠拟合，过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.稀疏性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5.高方差\n",
    "为什么线性回归模型中存在多个相关变量时，系数确定性变差，并呈现高方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6. Laplace平滑\n",
    "拉普拉斯平滑又称加1平滑，是比较常用的平滑方法，解决零概率问题。  \n",
    "所谓零概率问题，就是在计算新实例等概率时，如果某个分量在训练集中从没出现过，会导致整个实例等概率计算结果为0.针对文本分类问题就是当一个词语在训练集中没有出现过，那么该词语的概率为0，使用朴素贝叶斯法或者n-gram模型计算文本出现的概率时，连乘导致整个文本出现的概率也为0.这显然是不合理的，我们不能因为一个事件没有观测到而判断该事件发生的概率为0.  \n",
    "解决办法：分子加1，分母加空k，这里k代表类别数。\n",
    "\n",
    "## 7. 贝叶斯m-估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 8.共轭分布\n",
    "在贝叶斯统计中，如果后验分布和先验分布属于同类，则先验分布和后验分布被称为共轭分布，先验分布被称为似然函数的共轭先验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.最大似然和最大后验,贝叶斯估计，最小二乘之间的关系\n",
    "\n",
    "### 极大似然估计\n",
    "极大似然估计法由高斯和费希尔先后提出，是被使用最广泛的一种参数估计方法，该方法建立的依据是直观的极大似然原理 -- “最像”就是“最大似然”之意。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10.条件期望\n",
    "随机变量E(X|Y)为随机变量X关于随机变量Y的条件数学期望。随机变量E(X|Y)是随机变量Y的函数。故有：\n",
    "$$E[X]=E[E[X|Y]]$$\n",
    "对于任何关于X，Y的函数f(X,Y),有：  \n",
    "$$E[f(X,Y)]=E_XE[f(X,Y)|X]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic回归和极大似然之间的关系\n",
    "事实上，最小二乘可以由高斯噪声假设+极大似然估计推导出来。当然极大似然估计还可以推导出其他的loss function,比如logistic回归中，loss function是交叉熵."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## sklearn中 Random_state的作用\n",
    "random_state相当于随机数种子，即random.seed()。   \n",
    "设置random_state可以让每次划分训练集和验证集的时候都是完全一样的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 没有设置随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 37 64 98 81 93 30 70 62 23 ------------\n",
      "20 69 57 49 97 60 6 2 18 59 "
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(10):\n",
    "    print(random.randint(1,100),end=' ')\n",
    "print('------------')\n",
    "for i in range(10):\n",
    "    print(random.randint(1,100),end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置随机数种子(相同的随机种子）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 35 12 99 53 35 14 5 49 69 ------------\n",
      "7 35 12 99 53 35 14 5 49 69 "
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "for i in range(10):\n",
    "    print(random.randint(1,100),end=' ')\n",
    "print('------------')\n",
    "random.seed(123)\n",
    "for i in range(10):\n",
    "    print(random.randint(1,100),end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置不同的随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 58 60 56 50 83 6 80 94 67 "
     ]
    }
   ],
   "source": [
    "random.seed(456)\n",
    "for i in range(10):\n",
    "    print(random.randint(1,100),end=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
