{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PartI\n",
    "**编程实现对率回归，并给出西瓜数据集3.0$\\alpha$上的结果。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "\n",
    "# 输入西瓜数据集\n",
    "watermelon= np.array([[0.697,0.460,'是'],[0.774,0.376,'是'],[0.634,0.264,'是'],\n",
    "           [0.608,0.318,'是'],[0.556,0.215,'是'],[0.403,0.237,'是'],\n",
    "           [0.481,0.149,'是'],[0.437,0.211,'是'],[0.666,0.091,'否'],\n",
    "           [0.243,0.267,'否'],[0.245,0.057,'否'],[0.343,0.099,'否'],\n",
    "           [0.639,0.161,'否'],[0.657,0.198,'否'],[0.360,0.370,'否'],\n",
    "           [0.593,0.042,'否'],[0.719,0.103,'否']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 提取特征和类别\n",
    "features_raw = watermelon[:,0:2].astype('float')\n",
    "labels_raw = watermelon[:,-1][:,None]\n",
    "\n",
    "# 数据预处理\n",
    "x0 = np.ones((len(watermelon),1))\n",
    "features = np.column_stack((x0,features_raw))\n",
    "\n",
    "labels=list()\n",
    "for i in range(len(labels_raw)):\n",
    "    if labels_raw[i]=='是':\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "        \n",
    "## 拆分训练集和验证集\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,labels,test_size = 0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCSNgkFERNIoGEREJM3/B05QvaCSlDPBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1098ea400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画图看一下数据集情况\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx_0=[]\n",
    "idx_1=[]\n",
    "for idx, label in enumerate(labels):\n",
    "    if label == 1:\n",
    "        idx_1.append(idx)\n",
    "    else:\n",
    "        idx_0.append(idx)\n",
    "\n",
    "\n",
    "f1 = plt.figure(1)\n",
    "plt.title('watermelon')\n",
    "plt.xlabel('density')\n",
    "plt.ylabel('ratio_sugar')\n",
    "plt.scatter(features_raw[idx_0,0],features_raw[idx_0,1],marker='o',color='k',s=100,label='no')\n",
    "plt.scatter(features_raw[idx_1,0],features_raw[idx_1,1],marker='^',color='g',s=100,label='yes')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用梯度下降法实现对率回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def gradient_descent(train_feature,train_label,alpha,max_iterations):\n",
    "    m, n = train_feature.shape\n",
    "    label = np.mat(train_label).reshape(m,1)\n",
    "    \n",
    "    weights = np.ones((n,1))\n",
    "    for i in range(max_iterations):\n",
    "        error = label - sigmoid(np.dot(train_feature,weights))\n",
    "        weights = weights - alpha*(-np.dot(train_feature.T,error))\n",
    "    return weights\n",
    "\n",
    "def test_pred(test_feature, weights):\n",
    "    pred = np.dot(test_feature, weights)\n",
    "    pred_label = list()\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i]>= 0.5:\n",
    "            pred_label.append(1)\n",
    "        else:\n",
    "            pred_label.append(0)\n",
    "    return pred_label\n",
    "\n",
    "def test_score(pred_label,test_label):\n",
    "    count = 0\n",
    "    for i in range(len(pred_label)):\n",
    "        if pred_label[i] == test_label[i]:\n",
    "            count += 1\n",
    "    accuracy_score = count/len(pred_label)\n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "weights=gradient_descent(X_train,y_train,alpha=10,max_iterations=1000)\n",
    "pred_label=test_pred(X_test,weights)\n",
    "accuracy_score=test_score(pred_label, y_test)\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用随机梯度下降法实现对率回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def random_descent(train_feature, train_label,max_iterations,alpha):\n",
    "    m,n = train_feature.shape\n",
    "    label = train_label\n",
    "    \n",
    "    weights = np.ones(n)\n",
    "    for i in range(max_iterations):\n",
    "        for j in range(m):\n",
    "            error = label[j] - sigmoid(np.dot(train_feature[j],weights))\n",
    "            weights = weights +alpha*error*train_feature[j]\n",
    "    return weights\n",
    "def test_pred2(test_feature, weights):\n",
    "    pred = np.dot(test_feature, weights)\n",
    "    pred_label = list()\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i]>= 0.5:\n",
    "            pred_label.append(1)\n",
    "        else:\n",
    "            pred_label.append(0)\n",
    "    return pred_label\n",
    "\n",
    "def test_score2(pred_label,test_label):\n",
    "    count = 0\n",
    "    for i in range(len(pred_label)):\n",
    "        if pred_label[i] == test_label[i]:\n",
    "            count += 1\n",
    "    accuracy_score = count/len(pred_label)\n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "weights2=random_descent(X_train,y_train,alpha=5,max_iterations=1000)\n",
    "pred_label2=test_pred2(X_test,weights2)\n",
    "accuracy_score2=test_score2(pred_label2, y_test)\n",
    "print(accuracy_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用牛顿法实现对率回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def newton_method(train_feature, train_label, max_iterations):\n",
    "    m, n = train_feature.shape\n",
    "    label = np.mat(train_label).reshape(m,1)\n",
    "    \n",
    "    weights = np.ones((n,1))\n",
    "    for i in range(max_iterations):\n",
    "        error = label - sigmoid(np.dot(train_feature, weights))\n",
    "        deriv1 = -np.dot(train_feature.T,error)\n",
    "        v = np.dot(error,(1-error).T)\n",
    "        deriv2 = train_feature.T*v*train_feature\n",
    "        weights = weights - deriv2*deriv1\n",
    "    return weights\n",
    "def test_pred1(test_feature, weights):\n",
    "    pred= np.dot(test_feature,weights)\n",
    "    pred_label = list()\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] >= 0.5:\n",
    "            pred_label.append(1)\n",
    "        else:\n",
    "            pred_label.append(0)\n",
    "    return pred_label\n",
    "def test_score1(pred_label, test_label):\n",
    "    count = 0\n",
    "    for i in range(len(pred_label)):\n",
    "        if pred_label[i]==test_label[i]:\n",
    "            count +=1\n",
    "    accuracy_score = count/(len(pred_label))\n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "weights1=newton_method(X_train,y_train,max_iterations=500)\n",
    "pred_label1=test_pred1(X_test,weights1)\n",
    "accuracy_score1=test_score1(pred_label1, y_test)\n",
    "print(accuracy_score1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 采用sklearn逻辑斯蒂库函数直接拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2]\n",
      " [1 3]]\n",
      "0.666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train,y_train)\n",
    "pred_label = log.predict(X_test)\n",
    "score=accuracy_score(y_test,pred_label)\n",
    "\n",
    "print(confusion_matrix(y_test,pred_label))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II\n",
    "**选择两个UCI数据集，比较十折交叉验证法和留一法所估计出的对率回归的错误率。**\n",
    "### 1.选择Iris数据集  \n",
    "内部共150个数据集，3种类别，每类50个样本。  \n",
    "每次选择两类做二分类计算，做3轮计算。  \n",
    "每轮选择100个样本，10折交叉验证每次选45正-45反，剩余10个作为验证，一共10组，共验证100例。  \n",
    "留一法每次留一个作为验证集，一共做100组，也就是100例。  \n",
    "每个方法最终验证300例，直接比较错误分类的个数就能评价两种方法在数据集上的适用程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "# 读取数据 \n",
    "# 提取特征和类别\n",
    "features_raw = []\n",
    "labels = []\n",
    "with open('iris.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        lines = line.strip().split(',')\n",
    "        features_raw.append(lines[0:4])\n",
    "        labels.append(lines[-1])\n",
    "        \n",
    "# 数据预处理\n",
    "features = np.array(features_raw).astype('float')\n",
    "label_name = np.unique(labels)\n",
    "\n",
    "## 随机抽样，获得50个正例与50个反例的集合\n",
    "def data_preprocess(features_raw,labels_raw, labels_name):\n",
    "    # 将类别处理为0-1变量\n",
    "    label_pre = []\n",
    "    for i in range(len(labels_raw)):\n",
    "        if labels_raw[i] == labels_name:\n",
    "            label_pre.append(1)\n",
    "        else:\n",
    "            label_pre.append(0)\n",
    "    labels_pre = np.array(label_pre)\n",
    "    # 抽取等量的正类和负类使得样本平衡\n",
    "    id_0=[]\n",
    "    id_1 = []\n",
    "    for idl, label in enumerate(labels_pre):\n",
    "        if label == 1:\n",
    "            id_1.append(idl)\n",
    "        else:\n",
    "            id_0.append(idl)\n",
    "    new_id = id_1+sample(id_0, len(id_1))\n",
    "    features_new = features_raw[new_id]\n",
    "    labels_new = labels_pre[new_id]\n",
    "    return features_new, labels_new \n",
    "\n",
    "\n",
    "# 二分类类别：正类为'Iris-setosa'，其余是负类\n",
    "features1, y1_labels = data_preprocess(features, labels, label_name[0])\n",
    "\n",
    "# 二分类类别：正类为'Iris-versicolor'，其余是负类\n",
    "features2, y2_labels = data_preprocess(features, labels, label_name[1])\n",
    "\n",
    "# 二分类类别：正类为'Iris-virginica'，其余是负类\n",
    "features3, y3_labels = data_preprocess(features, labels, label_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用sklearn 实现交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the result of ten-fold crossvalidation :\n",
      "accuracy score of Iris-setosa is 1.0\n",
      "accuracy score of Iris-versicolor is 0.72\n",
      "accuracy score of Iris-virginica is 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cross_valid(feature_all, label_all, n_splits):\n",
    "    kf=StratifiedKFold(n_splits)\n",
    "    score_all=[]\n",
    "    for train_index, test_index in kf.split(feature_all,label_all):\n",
    "        X_train, X_test = feature_all[train_index],feature_all[test_index]\n",
    "        y_train, y_test = label_all[train_index],label_all[test_index]\n",
    "        log1=LogisticRegression()\n",
    "        log1.fit(X_train, y_train)\n",
    "        pred_test = log1.predict(X_test)\n",
    "        score = accuracy_score(y_test, pred_test)\n",
    "        score_all.append(score)\n",
    "    return score_all\n",
    "print('the result of ten-fold crossvalidation :') \n",
    "print('accuracy score of Iris-setosa is',np.mean(cross_valid(features1,y1_labels,n_splits=10)))\n",
    "print('accuracy score of Iris-versicolor is',np.mean(cross_valid(features2,y2_labels,n_splits=10)))\n",
    "print('accuracy score of Iris-virginica is',np.mean(cross_valid(features3,y3_labels,n_splits=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用sklearn 实现留一法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the result of leave-one-out :\n",
      "accuracy score of Iris-setosa is 1.0\n",
      "accuracy score of Iris-versicolor is 0.72\n",
      "accuracy score of Iris-virginica is 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def leave_one_out(feature_all, label_all):\n",
    "    loo = LeaveOneOut()\n",
    "    score_all=[]\n",
    "    for train_index, test_index in loo.split(feature_all,label_all):\n",
    "        X_train, X_test = feature_all[train_index],feature_all[test_index]\n",
    "        y_train, y_test = label_all[train_index],label_all[test_index]\n",
    "        log1=LogisticRegression()\n",
    "        log1.fit(X_train, y_train)\n",
    "        pred_test = log1.predict(X_test)\n",
    "        score = accuracy_score(y_test, pred_test)\n",
    "        score_all.append(score)\n",
    "    return score_all\n",
    "\n",
    "\n",
    "print('the result of leave-one-out :') \n",
    "print('accuracy score of Iris-setosa is',np.mean(leave_one_out(features1,y1_labels)))\n",
    "print('accuracy score of Iris-versicolor is',np.mean(leave_one_out(features2,y2_labels)))\n",
    "print('accuracy score of Iris-virginica is',np.mean(leave_one_out(features3,y3_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用之前的函数手动实现\n",
    "- 梯度下降法 实现交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the result of ten-fold crossvalidation :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of Iris-setosa is 1.0\n",
      "accuracy score of Iris-versicolor is 0.6\n",
      "accuracy score of Iris-virginica is 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def cross_valid1(feature_all, label_all, n_splits):\n",
    "    kf=StratifiedKFold(n_splits)\n",
    "    score_all=[]\n",
    "    for train_index, test_index in kf.split(feature_all,label_all):\n",
    "        X_train, X_test = feature_all[train_index],feature_all[test_index]\n",
    "        y_train, y_test = label_all[train_index],label_all[test_index]\n",
    "        weights=gradient_descent(X_train,y_train,alpha=10,max_iterations=1000)\n",
    "        pred_label=test_pred(X_test,weights)\n",
    "        score_all.append(test_score(pred_label, y_test))\n",
    "    return score_all\n",
    "print('the result of ten-fold crossvalidation :') \n",
    "print('accuracy score of Iris-setosa is',np.mean(cross_valid1(features1,y1_labels,n_splits=10)))\n",
    "print('accuracy score of Iris-versicolor is',np.mean(cross_valid1(features2,y2_labels,n_splits=10)))\n",
    "print('accuracy score of Iris-virginica is',np.mean(cross_valid1(features3,y3_labels,n_splits=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用梯度下降实现留一法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the result of leave-one-out :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score of Iris-setosa is 1.0\n",
      "accuracy score of Iris-versicolor is 0.57\n",
      "accuracy score of Iris-virginica is 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "def leave_one_out1(feature_all, label_all):\n",
    "    loo = LeaveOneOut()\n",
    "    score_all=[]\n",
    "    for train_index, test_index in loo.split(feature_all,label_all):\n",
    "        X_train, X_test = feature_all[train_index],feature_all[test_index]\n",
    "        y_train, y_test = label_all[train_index],label_all[test_index]\n",
    "        weights=gradient_descent(X_train,y_train,alpha=10,max_iterations=1000)\n",
    "        pred_label=test_pred(X_test,weights)\n",
    "        score_all.append(test_score(pred_label, y_test))\n",
    "    return score_all\n",
    "\n",
    "\n",
    "print('the result of leave-one-out :') \n",
    "print('accuracy score of Iris-setosa is',np.mean(leave_one_out1(features1,y1_labels)))\n",
    "print('accuracy score of Iris-versicolor is',np.mean(leave_one_out1(features2,y2_labels)))\n",
    "print('accuracy score of Iris-virginica is',np.mean(leave_one_out1(features3,y3_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.选择wine数据集\n",
    "- 这里我们只使用sklearn进行实现，其余实现方法与Iris相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "# 读取数据 \n",
    "# 提取特征和类别\n",
    "wine_features_raw = []\n",
    "wine_labels = []\n",
    "with open('wine.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        lines = line.strip().split(',')\n",
    "        wine_features_raw.append(lines[1:])\n",
    "        wine_labels.append(lines[0])  \n",
    "# 数据预处理        \n",
    "wine_features = np.array(wine_features_raw).astype('float')\n",
    "wine_label_name = np.unique(wine_labels)  \n",
    "\n",
    "# 二分类类别：正类为'Iris-setosa'，其余是负类\n",
    "wine_features1, wine_y1_labels = data_preprocess(wine_features, wine_labels, wine_label_name[0])\n",
    "\n",
    "# 二分类类别：正类为'Iris-versicolor'，其余是负类\n",
    "wine_features2, wine_y2_labels = data_preprocess(wine_features, wine_labels, wine_label_name[1])\n",
    "\n",
    "# 二分类类别：正类为'Iris-virginica'，其余是负类\n",
    "wine_features3, wine_y3_labels = data_preprocess(wine_features, wine_labels, wine_label_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the result of ten-fold crossvalidation :\n",
      "accuracy score of Iris-setosa is 0.958333333333\n",
      "accuracy score of Iris-versicolor is 0.944642857143\n",
      "accuracy score of Iris-virginica is 0.98\n"
     ]
    }
   ],
   "source": [
    "print('the result of ten-fold crossvalidation :') \n",
    "\n",
    "print('accuracy score of Iris-setosa is',np.mean(cross_valid(wine_features1,wine_y1_labels,n_splits=10)))\n",
    "print('accuracy score of Iris-versicolor is',np.mean(cross_valid(wine_features2,wine_y2_labels,n_splits=10)))\n",
    "print('accuracy score of Iris-virginica is',np.mean(cross_valid(wine_features3,wine_y3_labels,n_splits=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 留一法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the result of leave-one-out :\n",
      "accuracy score of Iris-setosa is 0.957627118644\n",
      "accuracy score of Iris-versicolor is 0.950704225352\n",
      "accuracy score of Iris-virginica is 0.96875\n"
     ]
    }
   ],
   "source": [
    "print('the result of leave-one-out :') \n",
    "print('accuracy score of Iris-setosa is',np.mean(leave_one_out(wine_features1,wine_y1_labels)))\n",
    "print('accuracy score of Iris-versicolor is',np.mean(leave_one_out(wine_features2,wine_y2_labels)))\n",
    "print('accuracy score of Iris-virginica is',np.mean(leave_one_out(wine_features3,wine_y3_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**结果**  \n",
    "由结果可见，十折交叉验证法和留一法结果基本一致。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
